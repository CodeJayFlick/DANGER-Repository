# Data collection scripts

The scripts involved in data collection are:

- clone_github_repos.py
- extract_files.py
- generate_ai_data.py
- clean_ai_data.py

Their uses are:

- clone_github_repos.py
    - This script pulls Github repositories, and sets them to their state at the specified date.
    - Parameters (set them in the script):
      - github_links - The link to each GitHub repo that should be cloned
      - date_to_access_string - The date the repos should be set to
    - Notes: If a GitHub repo did not exist prior to the specified date, it is simply not cloned at all.
- extract_files.py:
    - This script copies all files of a specified extension from specified folders, and puts them into one folder. 
    - Parameters (set them in the script):
        - folders_to_clone - A list of all the folders that code should be copied from.
        - output_folder_name - The name of the folder to put everything in.
        - extension - The extension to search for (include the '.')
    - Notes: 
        - In addition to the code, this script will create a CSV with the name about_samples.csv. This will have a row for each file written, with fields of "Filename", "AI" (will be marked False), and "Source".
          - If the folder specified is a GitHub repository, then the Source column in about_samples.csv will use the GitHub repo name as the source, rather than the folder name.
- generate_ai_data.py
    - This script allows generating AI code using an LLM through the Python library GPT4All. To generate unique code, the model translates human-written code from another language,
     using the input files in a given folder.
    - Parameters:
        - folder_to_translate_from: The folder of code that will be given as a prompt to the model
        - output_folder: The folder to write to
        - model_name: The name of the model to use. See GPT4All's documentation on what names are usable.
        - device: The device to run the model on. Most commonly one of {"cpu", "gpu", "cuda"}. See GPT4All's documentation on what devices are usable.
    - Notes:
        - Output must be cleaned by clean_ai_data.py.
        - In addition to the code, this script will create a CSV with the name about_samples.csv. This will have a row for each file written, with fields of "Filename", "AI" (will be marked True), and "Source" (will be given the model_name parameter).
- clean_ai_data.py
    - This script cleans data generated by generate_ai_data.py. For each file in input_folder's about_samples.csv, a new file in output_folder is created, with only the Python code added.
    - Parameters:
        - input_folder - The folder to read code from
        - output_folder - The folder to write to
    - Notes:
        - Parsing is done by extracting the code from the first code block (as originally used, there is generally only one code block).
        - If the file cannot be parsed (eg has no Python code block), it will be skipped.
        - A new about_samples.csv will be created in output_folder. It will be identical to the one in input_folder, except scripts that could not be parsed will not be included.
