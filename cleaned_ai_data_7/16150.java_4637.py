import numpy as np

class TicTacToe:
    def __init__(self):
        self.manager = None
        self.state = State(np.zeros(9), 1)
        self.replay_buffer = LruReplayBuffer()

    def reset(self):
        self.state.board.fill(0)
        self.state.turn = 1

    def close(self):
        if self.manager is not None:
            self.manager.close()
            self.manager = None

    def get_observation(self):
        return self.state.get_observaton(self.manager)

    def get_action_space(self):
        return self.state.get_action_space(self.manager)

    def step(self, action, training=False):
        move = int(action[0])
        if move < 0 or move >= 9:
            raise ValueError("Your move is out of bounds")
        if self.state.board[move] != 0:
            raise ValueError("Your move is on an already occupied space")

        pre_state = self.state
        self.state = State(pre_state.board.copy(), -pre_state.turn)
        self.state.board[move] = pre_state.turn

        step = TicTacToeStep(self.manager, pre_state, self.state, action)
        if training:
            self.replay_buffer.add_step(step)

        return step

    def get_batch(self):
        return self.replay_buffer.get_batch()

class State:
    def __init__(self, board, turn):
        self.board = board
        self.turn = turn

    def get_observaton(self, manager):
        return [manager.create(board), manager.create(turn)]

    def get_action_space(self, manager):
        action_space = []
        for i in range(9):
            if board[i] == 0:
                action_space.append(manager.create([i]))
        return action_space

class LruReplayBuffer:
    def __init__(self, batch_size=32, replay_buffer_size=10000):
        self.batch_size = batch_size
        self.replay_buffer_size = replay_buffer_size
        self.buffer = []

    def add_step(self, step):
        if len(self.buffer) < self.replay_buffer_size:
            self.buffer.append(step)
        else:
            self.buffer.pop(0)
            self.buffer.append(step)

    def get_batch(self):
        return [step for step in self.buffer[:self.batch_size]]

class TicTacToeStep:
    def __init__(self, manager, pre_state, post_state, action):
        self.manager = manager
        self.pre_state = pre_state
        self.post_state = post_state
        self.action = action

    def get_pre_observaton(self):
        return [manager.create(pre_state.board), manager.create(pre_state.turn)]

    def get_action(self):
        return self.action

    def get_post_observaton(self):
        return [manager.create(post_state.board), manager.create(post_state.turn)]

    def get_post_action_space(self):
        return post_state.get_action_space(self.manager)

    def get_reward(self):
        if post_state.is_draw():
            return 0
        elif post_state.turn == -1:
            return 1.0
        else:
            return -1.0

    def is_done(self):
        return self.post_state.is_draw() or self.post_state.get_winner() != 0

class Manager:
    pass

# Example usage:

manager = Manager()
replay_buffer = LruReplayBuffer(batch_size=32, replay_buffer_size=10000)
game = TicTacToe()

pre_state = game.state
action = [1]  # Move to the first position
step = game.step(action)

print(step.get_pre_observaton())
print(step.get_action())
print(step.get_post_observaton())

# Close the game when done.
game.close()
