import torch
from torchvision import datasets, transforms
from torch.nn.utils.rnn import pad_sequence
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.nn.modules.module import Module
from torch.nn.init import kaiming_uniform_
from torch.nn.functional import softmax

class LSTMBlock(Module):
    def __init__(self):
        super(LSTMBlock, self).__init__()
        self.lstm = torch.nn.LSTM(input_size=28*28, hidden_size=64, num_layers=1)
        self.fc = torch.nn.Linear(64, 10)

    def forward(self, x):
        h0 = torch.zeros((1, len(x), 64)).to(device)
        c0 = torch.zeros((1, len(x), 64)).to(device)
        
        out, _ = self.lstm(torch.tensor([x]).unsqueeze(0).float(), (h0,c0))
        out = softmax(self.fc(out.view(-1, 10)), dim=1)

        return out

class TrainMnistWithLSTM:
    def __init__(self):
        pass

    @staticmethod
    def run_example(args):
        arguments = Arguments().parse_args(args)
        
        if not arguments:
            return None
        
        try:
            model = torch.nn.Module("lstm")
            model.set_block(LSTMBlock())
            
            # get training and validation dataset
            train_set, test_set = datasets.MNIST(root='./data', download=True, transform=transforms.ToTensor(), train=True), datasets.MNIST(root='./data', download=True, transform=transforms.ToTensor(), train=False)
            
            # setup training configuration
            config = TrainMnistWithLSTM.setup_training_config(arguments)

            try:
                trainer = model.new_trainer(config)
                
                trainer.set_metrics(Metrics())
                
                input_shape = torch.Size([32, 1, 28, 28])
                
                # initialize trainer with proper input shape
                trainer.initialize(input_shape)
                
                EasyTrain.fit(trainer, arguments.get_epoch(), train_set, test_set)
                
                return trainer.get_training_result()
            except Exception as e:
                print(f"Error: {e}")
        except Exception as e:
            print(f"Error: {e}")

    @staticmethod
    def setup_training_config(arguments):
        output_dir = arguments.get_output_dir()

        listener = SaveModelTrainingListener(output_dir)
        
        listener.set_save_model_callback(
            lambda trainer: 
                result = trainer.get_training_result()
                model = trainer.get_model()
                accuracy = result.get_validate_evaluation("Accuracy")
                model.setProperty("Accuracy", f"{accuracy:.5f}")
                model.setProperty("Loss", f"{result.get_validate_loss():.5f}")
        )

        return DefaultTrainingConfig(Loss.softmax_cross_entropy_loss())
            .add_evaluator(Accuracy())
            .opt_devices(Engine.getInstance().get_devices(arguments.get_max_gpus()))
            .add_training_listeners(TrainingListener.Defaults.logging(output_dir))
            .add_training_listeners(listener)

    @staticmethod
    def get_dataset(usage, arguments):
        mnist = datasets.MNIST(root='./data', download=True, transform=transforms.ToTensor(), train=usage == "train")
        
        return mnist

if __name__ == "__main__":
    TrainMnistWithLSTM.run_example(sys.argv[1:])
