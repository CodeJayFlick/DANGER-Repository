# -*- coding: utf-8 -*-
"""Reformer_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mszNS63Fzx6TlZvato0h6yMtuW60h0fK
"""

import os
import pandas as pd
from sklearn.model_selection import train_test_split
import torch
from tqdm import tqdm
from torch.utils.data import Dataset, DataLoader, TensorDataset
import transformers
from transformers import ReformerModel, ReformerTokenizerFast
import get_model_training_data
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
import numpy as np
import torch.nn as nn
import torch.optim as optim
from tensorflow.keras.preprocessing.sequence import pad_sequences
import textblob



HUMAN_LABEL = 'human'
AI_LABEL = 'ai'

def load_dataframe():
  df = get_model_training_data.get_dataframe()

  print("Original Datagrame:")
  print(df)

  # Label processing for AI and Human Written code
  df['label'] = df['label'].str.lower().replace({'false': HUMAN_LABEL, 'true': AI_LABEL, 'no': HUMAN_LABEL, 'yes': AI_LABEL})

  print("\nDataframe after label processing:")
  print(df)

  # Dropping rows in which a label is NaN
  df = df.dropna(subset=['label'])

  # Mapping labels to numeric values
  df['msg_type'] = df['label'].map({HUMAN_LABEL: 0, AI_LABEL: 1})
  return df

# Function to create data loader from data
def create_dataloader(df):
    data = []
    df_reset = df.reset_index(drop = True)

    for i in range(0, len(df), chunk_size):
        chunk_texts = df.iloc[i:i+chunk_size-1, df_reset.columns.get_loc("code_sample")].tolist()
        chunk_labels = df.iloc[i:i+chunk_size-1, df_reset.columns.get_loc("msg_type")].tolist()

        # Convert texts to sequences of token IDs
        input_ids = tokenizer.texts_to_sequences(chunk_texts)

        input_ids = pad_sequences(input_ids, maxlen = max_length, padding = 'post', truncating = 'post')

        chunk = {
            "input_ids": input_ids,
            "labels": chunk_labels
        }
        data.append(chunk) # Appending implementations to the defined dictionary
    return data


# Updated function to pad both input_ids and labels
def prepare_data_loader(data, max_length, chunk_size, pad_label=-1):
    input_ids = []
    labels = []

    for item in data:
        # Pad input sequences to max_length
        padded_inputs = pad_sequences(item["input_ids"], maxlen=max_length, padding='post', truncating='post')

        # Pad labels to chunk_size, filling with pad_label
        padded_labels = item["labels"]
        if len(padded_labels) < chunk_size:
            padded_labels = np.pad(padded_labels, (0, chunk_size - len(padded_labels)), constant_values=pad_label)

        # Pad the inputs if necessary to chunk_size
        if len(padded_inputs) < chunk_size:
            padded_inputs = np.pad(padded_inputs, ((0, chunk_size - len(padded_inputs)), (0, 0)), 'constant')

        input_ids.append(torch.tensor(padded_inputs, dtype=torch.long))
        labels.append(torch.tensor(padded_labels, dtype=torch.long))

    # Stack inputs and labels with consistent sizes
    input_ids = torch.stack(input_ids, dim=0)  # [num_samples, chunk_size, max_length]
    labels = torch.stack(labels, dim=0)  # [num_samples, chunk_size]

    return TensorDataset(input_ids, labels)

# Define the model
class ReformerDataset(nn.Module):
    def __init__(self, d_model=256, vocab_size=50000, input_size = 1):
        super(ReformerDataset, self).__init__()
        self.embedding = nn.Embedding(vocab_size, d_model)
        self.lstm = nn.LSTM(input_size=d_model, hidden_size=d_model, batch_first=True)
        self.dense = nn.Linear(d_model, d_model)
        self.final_dense = nn.Linear(d_model, vocab_size)
        self.dropout = nn.Dropout(0.2)

    def forward(self, inputs):
        # Expand dimensions for LSTM compatibility
        #inputs = inputs.unsqueeze(-1).float()
        #inputs = inputs.squeeze(-1)
         # Check the shape of inputs before embedding

        print(f"Input shape before embedding: {inputs.shape}")

        # Ensure input shape is (batch_size, sequence_length)
        if len(inputs.shape) != 2:
            raise ValueError(f"Expected input shape to be 2D, got {inputs.shape}")

        # Pass through embedding layer
        embedded_inputs = self.embedding(inputs)

        # Ensure the embedded output is (batch_size, sequence_length, d_model)
        print(f"Shape after embedding: {embedded_inputs.shape}")

        # Check if the tensor is 3D (batch_size, sequence_length, d_model)
        if len(embedded_inputs.shape) != 3:
            raise ValueError(f"Expected embedded input shape to be 3D, got {embedded_inputs.shape}")

        # LSTM expects (batch_size, sequence_length, d_model)
        lstm_output, _ = self.lstm(embedded_inputs)

        # Check the output shape of the LSTM (batch_size, sequence_length, d_model)
        print(f"Shape after LSTM: {lstm_output.shape}")


        lstm_output = self.dropout(lstm_output[:, -1, :])  # Use the last output for classification
        dense_output = self.dense(lstm_output)
        output = self.final_dense(dense_output)
        return output

# Set requires_grad=True on the input tensor for autograd tracking
def train(model, train_data, optimizer, num_epochs=100):
    model.train()
    for epoch in range(num_epochs):
        epoch_loss = 0.0
        epoch_accuracy = 0.0
        batch_count = 0

        for inputs, labels in train_data:
          inputs = inputs.long()
          #labels = batch[1]
            #inputs = torch.tensor(batch['input_ids'], requires_grad=True)
            #labels = torch.tensor(batch['labels'])

          optimizer.zero_grad()
          outputs = model(inputs)
          loss = criterion(outputs.view(-1, outputs.size(-1)), labels.view(-1))
          loss.backward()

          # Optional gradient clipping
          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
          optimizer.step()

          # Calculate accuracy
          _, predicted = torch.max(outputs, 1)
          accuracy = (predicted == labels).float().mean()

          epoch_loss += loss.item()
          epoch_accuracy += accuracy.item()
          batch_count += 1

        avg_loss = epoch_loss / batch_count
        avg_accuracy = epoch_accuracy / batch_count

        if (epoch + 1) % 5 == 0:
            print(f"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}")



os.chdir('/content/drive/MyDrive/Reformer_Model_v3/DANGER-Repository-main')
df = load_dataframe()
train_df, test_df = train_test_split(df, test_size = 0.2, random_state = 42)

print(df.head())

tokenizer = Tokenizer(num_words = 50000)
all_texts = train_df['code_sample'].tolist() + test_df['code_sample'].tolist()
tokenizer.fit_on_texts(all_texts)

# Define chunk size
chunk_size = 32
max_length = 512

# Initialize tokenizer
tokenizer = Tokenizer(num_words=50000)

# Training code samples from training data as a list
all_texts = train_df['code_sample'].tolist() + test_df['code_sample'].tolist()
tokenizer.fit_on_texts(all_texts) # Method to fit all code samples

# Prepare the DataLoader
train_dataset = prepare_data_loader(train_data, max_length=max_length, chunk_size=chunk_size)
train_dataloader = DataLoader(train_dataset, batch_size=chunk_size, shuffle=True)

# Initialize the model, loss, and optimizer
model = ReformerDataset()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-8)

# Prepare DataLoader for PyTorch
#train_dataloader = DataLoader(train_data, batch_size=chunk_size, shuffle=True)
train(model, train_dataloader, optimizer)


# Define chunk size
chunk_size = 32
max_length = 512

# Initialize tokenizer
tokenizer = Tokenizer(num_words=50000)

# Training code samples from training data as a list
all_texts = train_df['code_sample'].tolist() + test_df['code_sample'].tolist()
tokenizer.fit_on_texts(all_texts) # Method to fit all code samples


# Create train and test data loaders
train_data = create_dataloader(train_df)
test_data = create_dataloader(test_df)

# Defining a class in order to implement the transformer model with additional dropout and byte length for forward feeding and max length
class Reformer_Dataset(tf.keras.layers.Layer):
    def __init__(self, d_model=256, d_ff=512, max_length=512, vocab_size=50000, chunk_size=32): # Custom dense layers and LSTM to simulate Reformer model process
        super(Reformer_Dataset, self).__init__() # Initalizes the reformer model to activate

        self.d_model = d_model
        self.d_ff = d_ff
        self.max_length = max_length # Output Layer
        self.chunk_size = chunk_size

        self.lstm = tf.keras.layers.LSTM(self.d_model)  # Using LSTM here for the example
        self.dense = tf.keras.layers.Dense(self.d_model)
        self.final_dense = tf.keras.layers.Dense(1)
        self.dropout = tf.keras.layers.Dropout(0.2)

    # Function to call the reformer model input
    def call(self, inputs):
      inputs = tf.expand_dims(inputs, -1) # Assignment to expand the dimensions to input shape

      # Assuming inputs are already tokenized
      #reformer_output = tf.keras.layers.LSTM(self.d_model)(inputs)  # Using LSTM here for the example
      #dense_output = tf.keras.layers.Dense(self.d_model)(reformer_output)
      #output = tf.keras.layers.Dense(1)(dense_output[:, 1, :])  # Taking the output of the second token
      #output = tf.keras.layers.Dense(1)(dense_output)

      reformer_output = self.lstm(inputs)
      reformer_output = self.dropout(reformer_output)
      dense_output = self.dense(reformer_output)
      output = self.final_dense(dense_output)
      return output

# Create Reformer Layer and Model
reformer_layer = Reformer_Dataset()

model = tf.keras.Sequential([reformer_layer])

#optimizer = tf.keras.optimizers.Adam(learning_rate=1e-8)

# Compile the model
model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-8))

# Function to compute gradient clipping to prevent nan values within loss
def train_model_with_gradient_clipping(model, train_data, optimizer, max_gradient_norm = 1.0, num_epochs = 100):
  train_loss = []
  train_accuracy = []

  for epoch in range(num_epochs):
    epoch_loss = 0.0
    epoch_accuracy = 0.0
    batch_count = 0

    for batch in train_data:
      input_tensor = tf.convert_to_tensor(batch["input_ids"], dtype = tf.int32)
      label_tensor = tf.convert_to_tensor(batch["labels"], dtype = tf.int32)
      dataset = tf.data.Dataset.from_tensor_slices((input_tensor, label_tensor)).batch(chunk_size)

      for inputs, labels in dataset:
        with tf.GradientTape() as tape:
          predictions = model(inputs)
          loss_value = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)(labels, predictions)

      compute_gradients = tape.gradient(loss_value, model.trainable_variables)
      clipped_gradients = [tf.clip_by_norm(g, max_gradient_norm) if g is not None else None for g in compute_gradients]
      optimizer.apply_gradients(zip(clipped_gradients, model.trainable_variables))

      accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(predictions, axis=-1, output_type = tf.int32), labels), tf.float32))

      epoch_loss += loss_value.numpy()
      epoch_accuracy += accuracy.numpy()
      batch_count += 1

    train_loss.append(epoch_loss / batch_count)
    train_accuracy.append(epoch_accuracy / batch_count)

    if (epoch + 1) % 5 == 0:
      print(f"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss[-1]:.4f}, Accuracy: {train_accuracy[-1]:.4f}")
      #model.save_weights(f"model_weights_epoch_{epoch + 1}.h5")
  return train_loss, train_accuracy

train_model_with_gradient_clipping(model, train_data, optimizer)
  #for batch in train_data:
    # Convert lists of input_ids and labels into tensors
    #input_tensor = tf.convert_to_tensor(batch["input_ids"], dtype=tf.int32)
    #label_tensor = tf.convert_to_tensor(batch["labels"], dtype=tf.int32)

    # Create a TensorFlow dataset for batch processing
    #dataset = tf.data.Dataset.from_tensor_slices((input_tensor, label_tensor)).batch(chunk_size)

    # Iterate over the dataset to make predictions and calculate loss and accuracy
    #for inputs, labels in dataset:
        #with tf.GradientTape() as tape:
            # Forward pass
            #predictions = model(inputs)
            # Loss calculation
            #loss_value = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)(labels, predictions)

        #labels = tf.cast(labels, tf.int64)

        # Computing gradients
        #compute_gradients = tape.gradient(loss_value, model.trainable_variables)

        # Clipping gradients to prevent NAN values within loss
        #clipped_gradients = [tf.clip_by_norm(g, max_gradient_norm) if g is not None else None for g in compute_gradients]

        # Apply gradients to update model parameteres
        #optimizer.apply_gradients(zip(clipped_gradients, model.trainable_variables))

        # Accuracy calculation
        #accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(predictions, axis=-1, output_type = tf.int64), labels), tf.float32))

        # Display loss and accuracy
        #print(f"Accuracy: {accuracy.numpy():.4f}, Loss: {loss_value.numpy():.2f} ")


# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-7)

#train_model_with_gradient_clipping(model, train_data, optimizer)